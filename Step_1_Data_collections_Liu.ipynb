{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.70 Safari/537.36'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we choose the data columns we want from the dataset, in order to save storage\n",
    "words_count = ['summary','space','description','neighborhood_overview','notes',\\\n",
    "               'transit','access','interaction','house_rules']\n",
    "\n",
    "house_attributes = ['property_type', 'room_type',\\\n",
    "                    'accommodates', 'bathrooms', 'bedrooms', 'beds','amenities']\n",
    "\n",
    "host_attributes_1 = ['host_id','host_is_superhost']\n",
    "\n",
    "host_attributes_2 = ['host_id','host_response_time', 'host_response_rate', 'host_acceptance_rate',\\\n",
    "                    'host_identity_verified']\n",
    "\n",
    "review_1 = ['number_of_reviews','review_scores_rating']\n",
    "\n",
    "review_2 = ['review_scores_accuracy', 'review_scores_checkin','review_scores_cleanliness',\\\n",
    "            'review_scores_communication','review_scores_location', 'review_scores_rating',\\\n",
    "            'review_scores_value']\n",
    "\n",
    "policies = ['instant_bookable','cancellation_policy','minimum_nights']\n",
    "\n",
    "location_ = ['latitude','longitude']\n",
    "\n",
    "df_y = ['price']\n",
    "\n",
    "columns = [['id'],words_count, host_attributes_1, host_attributes_2,\\\n",
    "           review_1,review_2,house_attributes,policies,location_,df_y]\n",
    "\n",
    "columns_m =  list(itertools.chain.from_iterable(columns)) \n",
    "columns_ = list(set(columns_m))\n",
    "\n",
    "## store the variables\n",
    "%store words_count \n",
    "%store host_attributes_1\n",
    "%store host_attributes_2\n",
    "%store review_1\n",
    "%store review_2\n",
    "%store house_attributes\n",
    "%store policies\n",
    "%store location_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insideairbnb = 'http://insideairbnb.com/get-the-data.html'\n",
    "r = rq.get(insideairbnb)\n",
    "\n",
    "def _getUrls_(res):  ## getUrls from the html page\n",
    "    hrefs = []\n",
    "    soup = BS(res.text, 'html.parser')\n",
    "    main_content = soup.find(class_='table table-hover table-striped beijing')\n",
    "    table = main_content.findAll('a',href=True)\n",
    "    listingnum = [i for i in range(len(table)) if i % 7 == 0]\n",
    "    for i in listingnum:\n",
    "        url = str(table[i]).split('\" onclick=\"var')[0][9:]\n",
    "        hrefs.append(url)\n",
    "    return(hrefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read and store 17 files, but took too many storage, therefore we used method 2\n",
    "for url in _getUrls_(r):\n",
    "    r = rq.get(url)\n",
    "    url_parts = url.split('/')\n",
    "    file_name = url_parts[-1].split('.')[0]+'-'+url_parts[-3]\n",
    "    if r.status_code == 200:\n",
    "        with open('{}.zip.gz'.format(file_name),'wb') as f:\n",
    "            f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read url directly from the website\n",
    "for url in _getUrls_(r):\n",
    "    try:\n",
    "        if url == 'http://data.insideairbnb.com/china/beijing/beijing/2019-09-23/data/listings.csv.gz': \n",
    "            df_listings = pd.read_csv(url,error_bad_lines=False, index_col=False, dtype='unicode',usecols =columns_)\n",
    "            df_listings['year'] = url[-31:-21]\n",
    "        else:\n",
    "            df = pd.read_csv(url,error_bad_lines=False, index_col=False, dtype='unicode',usecols =columns_)\n",
    "            df['year'] = url[-31:-21]\n",
    "            df_listings = df_listings.append(df)\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explore the files as a csv file\n",
    "df_listings.to_csv('listing_1_yr_beijing.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
